{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: xgboost\n",
      "Warning message:\n",
      "\"package 'xgboost' was built under R version 3.4.3\""
     ]
    }
   ],
   "source": [
    "require(xgboost)\n",
    "# load in the agaricus dataset\n",
    "data(agaricus.train, package='xgboost')\n",
    "data(agaricus.test, package='xgboost')\n",
    "dtrain <- xgb.DMatrix(agaricus.train$data, label = agaricus.train$label)\n",
    "dtest <- xgb.DMatrix(agaricus.test$data, label = agaricus.test$label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running cross validation\n",
      "[1]\ttrain-error:0.046523+0.002404\ttest-error:0.046526+0.009616 \n",
      "[2]\ttrain-error:0.022263+0.001024\ttest-error:0.022264+0.004100 \n"
     ]
    }
   ],
   "source": [
    "nround <- 2\n",
    "param <- list(max_depth=2, eta=1, silent=1, nthread=2, objective='binary:logistic')\n",
    "\n",
    "cat('running cross validation\\n')\n",
    "# do cross validation, this will print result out as\n",
    "# [iteration]  metric_name:mean_value+std_value\n",
    "# std_value is standard deviation of the metric\n",
    "xgb.cv(param, dtrain, nround, nfold=5, metrics={'error'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running cross validation, disable standard deviation display\n",
      "[1]\ttrain-error:0.046522+0.000825\ttest-error:0.046522+0.003304 \n",
      "[2]\ttrain-error:0.022263+0.000404\ttest-error:0.022263+0.001616 \n"
     ]
    }
   ],
   "source": [
    "cat('running cross validation, disable standard deviation display\\n')\n",
    "# do cross validation, this will print result out as\n",
    "# [iteration]  metric_name:mean_value+std_value\n",
    "# std_value is standard deviation of the metric\n",
    "xgb.cv(param, dtrain, nround, nfold=5,\n",
    "       metrics='error', showsd = FALSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"running cross validation, with cutomsized loss function\"\n",
      "[1]\ttrain-error:0.046522+0.000979\ttest-error:0.046521+0.003915 \n",
      "[2]\ttrain-error:0.022263+0.000854\ttest-error:0.022261+0.003415 \n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# you can also do cross validation with cutomized loss function\n",
    "# See custom_objective.R\n",
    "##\n",
    "print ('running cross validation, with cutomsized loss function')\n",
    "\n",
    "logregobj <- function(preds, dtrain) {\n",
    "  labels <- getinfo(dtrain, \"label\")\n",
    "  preds <- 1/(1 + exp(-preds))\n",
    "  grad <- preds - labels\n",
    "  hess <- preds * (1 - preds)\n",
    "  return(list(grad = grad, hess = hess))\n",
    "}\n",
    "evalerror <- function(preds, dtrain) {\n",
    "  labels <- getinfo(dtrain, \"label\")\n",
    "  err <- as.numeric(sum(labels != (preds > 0)))/length(labels)\n",
    "  return(list(metric = \"error\", value = err))\n",
    "}\n",
    "\n",
    "param <- list(max_depth=2, eta=1, silent=1,\n",
    "              objective = logregobj, eval_metric = evalerror)\n",
    "# train with customized objective\n",
    "xgb.cv(params = param, data = dtrain, nrounds = nround, nfold = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-error:0.046522+0.001026\ttest-error:0.046522+0.004105 \n",
      "[2]\ttrain-error:0.022263+0.000388\ttest-error:0.022264+0.001550 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>iter</th><th scope=col>train_error_mean</th><th scope=col>train_error_std</th><th scope=col>test_error_mean</th><th scope=col>test_error_std</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1           </td><td>0.04652231  </td><td>0.0010256487</td><td>0.04652188  </td><td>0.004104821 </td></tr>\n",
       "\t<tr><td>2           </td><td>0.02226323  </td><td>0.0003877655</td><td>0.02226424  </td><td>0.001549918 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " iter & train\\_error\\_mean & train\\_error\\_std & test\\_error\\_mean & test\\_error\\_std\\\\\n",
       "\\hline\n",
       "\t 1            & 0.04652231   & 0.0010256487 & 0.04652188   & 0.004104821 \\\\\n",
       "\t 2            & 0.02226323   & 0.0003877655 & 0.02226424   & 0.001549918 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "iter | train_error_mean | train_error_std | test_error_mean | test_error_std | \n",
       "|---|---|\n",
       "| 1            | 0.04652231   | 0.0010256487 | 0.04652188   | 0.004104821  | \n",
       "| 2            | 0.02226323   | 0.0003877655 | 0.02226424   | 0.001549918  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  iter train_error_mean train_error_std test_error_mean test_error_std\n",
       "1 1    0.04652231       0.0010256487    0.04652188      0.004104821   \n",
       "2 2    0.02226323       0.0003877655    0.02226424      0.001549918   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "6513"
      ],
      "text/latex": [
       "6513"
      ],
      "text/markdown": [
       "6513"
      ],
      "text/plain": [
       "[1] 6513"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do cross validation with prediction values for each fold\n",
    "res <- xgb.cv(params = param, data = dtrain, nrounds = nround, nfold = 5, prediction = TRUE)\n",
    "res$evaluation_log\n",
    "length(res$pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict leaf indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: data.table\n",
      "Loading required package: Matrix\n"
     ]
    }
   ],
   "source": [
    "require(xgboost)\n",
    "require(data.table)\n",
    "require(Matrix)\n",
    "\n",
    "set.seed(1982)\n",
    "\n",
    "# load in the agaricus dataset\n",
    "data(agaricus.train, package='xgboost')\n",
    "data(agaricus.test, package='xgboost')\n",
    "dtrain <- xgb.DMatrix(data = agaricus.train$data, label = agaricus.train$label)\n",
    "dtest <- xgb.DMatrix(data = agaricus.test$data, label = agaricus.test$label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "param <- list(max_depth=2, eta=1, silent=1, objective='binary:logistic')\n",
    "nround = 4\n",
    "\n",
    "# training the model for two rounds\n",
    "bst = xgb.train(params = param, data = dtrain, nrounds = nround, nthread = 2)\n",
    "\n",
    "# Model accuracy without new features\n",
    "accuracy.before <- sum((predict(bst, agaricus.test$data) >= 0.5) == agaricus.test$label)/\n",
    "                 length(agaricus.test$label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.981998758535071"
      ],
      "text/latex": [
       "0.981998758535071"
      ],
      "text/markdown": [
       "0.981998758535071"
      ],
      "text/plain": [
       "[1] 0.9819988"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy.before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>4</td><td>3</td><td>5</td><td>4</td></tr>\n",
       "\t<tr><td>3</td><td>3</td><td>5</td><td>3</td></tr>\n",
       "\t<tr><td>4</td><td>3</td><td>5</td><td>4</td></tr>\n",
       "\t<tr><td>4</td><td>3</td><td>5</td><td>4</td></tr>\n",
       "\t<tr><td>5</td><td>4</td><td>5</td><td>3</td></tr>\n",
       "\t<tr><td>3</td><td>3</td><td>5</td><td>3</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{llll}\n",
       "\t 4 & 3 & 5 & 4\\\\\n",
       "\t 3 & 3 & 5 & 3\\\\\n",
       "\t 4 & 3 & 5 & 4\\\\\n",
       "\t 4 & 3 & 5 & 4\\\\\n",
       "\t 5 & 4 & 5 & 3\\\\\n",
       "\t 3 & 3 & 5 & 3\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 4 | 3 | 5 | 4 | \n",
       "| 3 | 3 | 5 | 3 | \n",
       "| 4 | 3 | 5 | 4 | \n",
       "| 4 | 3 | 5 | 4 | \n",
       "| 5 | 4 | 5 | 3 | \n",
       "| 3 | 3 | 5 | 3 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     [,1] [,2] [,3] [,4]\n",
       "[1,] 4    3    5    4   \n",
       "[2,] 3    3    5    3   \n",
       "[3,] 4    3    5    4   \n",
       "[4,] 4    3    5    4   \n",
       "[5,] 5    4    5    3   \n",
       "[6,] 3    3    5    3   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# by default, we predict using all the trees\n",
    "pred_with_leaf = predict(bst, dtest, predleaf = TRUE)\n",
    "head(pred_with_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "create.new.tree.features <- function(model, original.features){\n",
    "  pred_with_leaf <- predict(model, original.features, predleaf = TRUE)\n",
    "  cols <- list()\n",
    "  for(i in 1:model$niter){\n",
    "    # max is not the real max but it s not important for the purpose of adding features\n",
    "    leaf.id <- sort(unique(pred_with_leaf[,i]))\n",
    "    cols[[i]] <- factor(x = pred_with_leaf[,i], level = leaf.id)\n",
    "  }\n",
    "  cBind(original.features, sparse.model.matrix( ~ . -1, as.data.frame(cols)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert previous features to one hot encoding\n",
    "new.features.train <- create.new.tree.features(bst, agaricus.train$data)\n",
    "new.features.test <- create.new.tree.features(bst, agaricus.test$data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning with new features\n",
    "new.dtrain <- xgb.DMatrix(data = new.features.train, label = agaricus.train$label)\n",
    "new.dtest <- xgb.DMatrix(data = new.features.test, label = agaricus.test$label)\n",
    "watchlist <- list(train = new.dtrain)\n",
    "bst <- xgb.train(params = param, data = new.dtrain, nrounds = nround, nthread = 2)\n",
    "\n",
    "# Model accuracy with new features\n",
    "accuracy.after <- sum((predict(bst, new.dtest) >= 0.5) == agaricus.test$label) /\n",
    "                    length(agaricus.test$label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "param <- list(max_depth=2, eta=1, objective='binary:logistic', booster='dart')\n",
    "nround = 1000\n",
    "\n",
    "# training the model for two rounds\n",
    "bst_dart = xgb.train(params = param, data = dtrain, nrounds = nround, nthread = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "##### xgb.Booster\n",
       "raw: 202.9 Kb \n",
       "call:\n",
       "  xgb.train(params = param, data = dtrain, nrounds = nround, nthread = 2)\n",
       "params (as set within xgb.train):\n",
       "  max_depth = \"2\", eta = \"1\", objective = \"binary:logistic\", booster = \"dart\", nthread = \"2\", silent = \"1\"\n",
       "xgb.attributes:\n",
       "  niter\n",
       "callbacks:\n",
       "  cb.print.evaluation(period = print_every_n)\n",
       "niter: 1000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bst_dart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model accuracy with new features\n",
    "accuracy.after <- sum((predict(bst_dart, new.dtest) >= 0.5) == agaricus.test$label) /\n",
    "                    length(agaricus.test$label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monotonic Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-error:0.046522 \n",
      "Will train until train_error hasn't improved in 10 rounds.\n",
      "\n",
      "[2]\ttrain-error:0.022263 \n",
      "[3]\ttrain-error:0.007063 \n",
      "[4]\ttrain-error:0.015200 \n",
      "[5]\ttrain-error:0.007063 \n",
      "[6]\ttrain-error:0.001228 \n",
      "[7]\ttrain-error:0.001228 \n",
      "[8]\ttrain-error:0.001228 \n",
      "[9]\ttrain-error:0.001228 \n",
      "[10]\ttrain-error:0.000000 \n",
      "[11]\ttrain-error:0.000000 \n",
      "[12]\ttrain-error:0.000000 \n",
      "[13]\ttrain-error:0.000000 \n",
      "[14]\ttrain-error:0.000000 \n",
      "[15]\ttrain-error:0.000000 \n",
      "[16]\ttrain-error:0.000000 \n",
      "[17]\ttrain-error:0.000000 \n",
      "[18]\ttrain-error:0.000000 \n",
      "[19]\ttrain-error:0.000000 \n",
      "[20]\ttrain-error:0.000000 \n",
      "Stopping. Best iteration:\n",
      "[10]\ttrain-error:0.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_no_constraints = xgb.train(param, dtrain, nrounds = nround, watchlist = watchlist,\n",
    "                                 num_boost_round = 1000, \n",
    "                                 early_stopping_rounds = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-error:0.046522 \n",
      "Will train until train_error hasn't improved in 10 rounds.\n",
      "\n",
      "[2]\ttrain-error:0.022263 \n",
      "[3]\ttrain-error:0.007063 \n",
      "[4]\ttrain-error:0.015200 \n",
      "[5]\ttrain-error:0.007063 \n",
      "[6]\ttrain-error:0.001228 \n",
      "[7]\ttrain-error:0.001228 \n",
      "[8]\ttrain-error:0.001228 \n",
      "[9]\ttrain-error:0.001228 \n",
      "[10]\ttrain-error:0.000000 \n",
      "[11]\ttrain-error:0.000000 \n",
      "[12]\ttrain-error:0.000000 \n",
      "[13]\ttrain-error:0.000000 \n",
      "[14]\ttrain-error:0.000000 \n",
      "[15]\ttrain-error:0.000000 \n",
      "[16]\ttrain-error:0.000000 \n",
      "[17]\ttrain-error:0.000000 \n",
      "[18]\ttrain-error:0.000000 \n",
      "[19]\ttrain-error:0.000000 \n",
      "[20]\ttrain-error:0.000000 \n",
      "Stopping. Best iteration:\n",
      "[10]\ttrain-error:0.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params_constrained <- list(max_depth=2, eta=1, objective='binary:logistic', booster='dart',\n",
    "                          monotone_constraints = rep(0,126))\n",
    "\n",
    "model_with_constraints = xgb.train(params_constrained, dtrain, nrounds = nround,\n",
    "                                   watchlist = watchlist, \n",
    "                                   num_boost_round = 1000, \n",
    "                                   early_stopping_rounds = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R [Anaconda3]",
   "language": "R",
   "name": "R [Anaconda3]"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
